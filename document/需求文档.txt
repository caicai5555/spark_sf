第一个步骤就是数据调研（就是对底层基于的基础数据的表结构进行调研、分析和研究）；
第二个步骤，就是需求分析（在实际的企业中，需求分析，可能会比这里更加复杂很多)；

在互联网企业中，需求分析，首先就是要跟PM，就是产品经理，也就是负责设计你开发的大数据平台产品的人，去大量开会，去沟通需求的细节；
此外，你自己还得根据产品经理编写的需求文档，可能还会自己设计一些产品原型图出来，让你看，去看，去研究
然后第三点，可能还需要作为一个项目的技术leader，去跟你的项目组内的成员，去讲解和讨论需求，要确保组内所有成员，
都对需求清晰的理解了）


一，需求分析（用户行为模块分析）
统计出符合条件的session中，访问时长在1s~3s、4s~6s、7s~9s、10s~30s、30s~60s、1m~3m、3m~10m、10m~30m、30m
以上各个范围内的session占比；访问步长在1~3、4~6、7~9、10~30、30~60、60以上各个范围内的session占比


二，技术选型
统计出符合条件的session中，访问时长在1s~3s、4s~6s、7s~9s、10s~30s、30s~60s、1m~3m、3m~10m、10m~30m、30m以上各个范围内的session占比；
访问步长在1~3、4~6、7~9、10~30、30~60、60以上各个范围内的session占比

session访问时长，也就是说一个session对应的开始的action，到结束的action，之间的时间范围；还有，就是访问步长，指的是，一个session执行期间内，
依次点击过多少个页面，比如说，一次session，维持了1分钟，那么访问时长就是1m，然后在这1分钟内，点击了10个页面，那么session的访问步长，就是10.
比如说，符合第一步筛选出来的session的数量大概是有1000万个。那么里面，我们要计算出，访问时长在1s~3s内的session的数量，并除以符合条件的总
session数量（比如1000万），比如是100万/1000万，那么1s~3s内的session占比就是10%。依次类推，这里说的统计，就是这个意思

这个功能的作用，其实就是，可以让人从全局的角度看到，符合某些条件的用户群体，使用我们的产品的一些习惯。比如大多数人，到底是会在产品中停留多长时间，大多数人，
会在一次使用产品的过程中，访问多少个页面。那么对于使用者来说，有一个全局和清晰的认识


三，技术难点
1，封装JDBC
2，spark读取hbase数据
3，自定义累加器
4，fastjson的使用


四，代码实现思路
1，从javaEE系统中读取任务相关参数
    封装JDBC，Dao
2，从hbase中过滤出我们需要的数据（session）
    扫描器，封装数据成rdd
3，分析业务（使用自定义累加器）
    各种自定义方法


